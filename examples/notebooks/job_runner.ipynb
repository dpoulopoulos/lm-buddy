{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook illustrates how to use LM Buddy as a library to run jobs directly on the host machine.\n",
    "\n",
    "Jobs are fully specified by a `lm_buddy.jobs.configs.LMBuddyJobConfig` \n",
    "and are executed with the `lm_buddy.run_job` method.\n",
    "\n",
    "**Warning**: This workflow is still considered experimental.\n",
    "Some jobs depend on external services (e.g., W&B, Ray cluster) and host-machine GPU resources,\n",
    "and may not work without a properly configured local environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lm_buddy\n",
    "from lm_buddy.jobs.configs import (\n",
    "    FinetuningJobConfig,\n",
    "    FinetuningRayConfig,\n",
    "    LMHarnessJobConfig,\n",
    "    LMHarnessEvaluatorConfig,\n",
    ")\n",
    "from lm_buddy.integrations.huggingface import (\n",
    "    HuggingFaceRepoConfig,\n",
    "    AutoModelConfig,\n",
    "    TextDatasetConfig,\n",
    "    TrainerConfig,\n",
    "    AdapterConfig,\n",
    ")\n",
    "from lm_buddy.integrations.wandb import WandbRunConfig\n",
    "\n",
    "# Third party\n",
    "import torch\n",
    "from peft import PeftType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HuggingFace assets\n",
    "model_config = AutoModelConfig(\n",
    "    load_from=HuggingFaceRepoConfig(repo_id=\"distilgpt2\"),\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "dataset_config = TextDatasetConfig(\n",
    "    load_from=HuggingFaceRepoConfig(repo_id=\"imdb\"),\n",
    "    split=\"train[:100]\",\n",
    "    text_field=\"text\",\n",
    ")\n",
    "trainer_config = TrainerConfig(\n",
    "    max_seq_length=256,\n",
    "    num_train_epochs=1,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=1,\n",
    "    save_strategy=\"epoch\",\n",
    "    save_steps=1,\n",
    ")\n",
    "adapter_config = AdapterConfig(\n",
    "    peft_type=\"LORA\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Job setup\n",
    "tracking_config = WandbRunConfig(\n",
    "    name=\"example-fietuning\",\n",
    "    project=\"sfriedowitz-dev\",\n",
    ")\n",
    "ray_config = FinetuningRayConfig(\n",
    "    use_gpu=False,  # In case the local machine does not have a GPU\n",
    "    num_workers=2,\n",
    ")\n",
    "job_config = FinetuningJobConfig(\n",
    "    model=model_config,\n",
    "    dataset=dataset_config,\n",
    "    trainer=trainer_config,\n",
    "    adapter=adapter_config,\n",
    "    tracking=tracking_config,\n",
    "    ray=ray_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-16 15:09:37,329\tERROR tune_controller.py:1374 -- Trial task failed for trial TorchTrainer_08e3c_00000\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sfriedowitz/miniconda3/envs/lm-buddy/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/Users/sfriedowitz/miniconda3/envs/lm-buddy/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/sfriedowitz/miniconda3/envs/lm-buddy/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/sfriedowitz/miniconda3/envs/lm-buddy/lib/python3.10/site-packages/ray/_private/worker.py\", line 2624, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::_Inner.train()\u001b[39m (pid=96385, ip=127.0.0.1, actor_id=bf3aee7e1968b8c89f1f5e8a01000000, repr=TorchTrainer)\n",
      "  File \"/Users/sfriedowitz/miniconda3/envs/lm-buddy/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 342, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/Users/sfriedowitz/miniconda3/envs/lm-buddy/lib/python3.10/site-packages/ray/train/_internal/utils.py\", line 43, in check_for_failure\n",
      "    ray.get(object_ref)\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::_RayTrainWorker__execute.get_next()\u001b[39m (pid=96405, ip=127.0.0.1, actor_id=b4353c84bc8b6902aefc6ed601000000, repr=<ray.train._internal.worker_group.RayTrainWorker object at 0x11d8edc90>)\n",
      "  File \"/Users/sfriedowitz/miniconda3/envs/lm-buddy/lib/python3.10/site-packages/ray/train/_internal/worker_group.py\", line 33, in __execute\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/Users/sfriedowitz/miniconda3/envs/lm-buddy/lib/python3.10/site-packages/ray/train/_internal/utils.py\", line 118, in discard_return_wrapper\n",
      "    train_func(*args, **kwargs)\n",
      "  File \"/Users/sfriedowitz/workspace/lm_buddy/src/lm_buddy/jobs/_entrypoints/finetuning.py\", line 82, in training_function\n",
      "    load_and_train(config, artifact_loader)\n",
      "  File \"/Users/sfriedowitz/workspace/lm_buddy/src/lm_buddy/jobs/_entrypoints/finetuning.py\", line 62, in load_and_train\n",
      "    trainer.train()\n",
      "  File \"/Users/sfriedowitz/miniconda3/envs/lm-buddy/lib/python3.10/site-packages/trl/trainer/sft_trainer.py\", line 323, in train\n",
      "    output = super().train(*args, **kwargs)\n",
      "  File \"/Users/sfriedowitz/miniconda3/envs/lm-buddy/lib/python3.10/site-packages/transformers/trainer.py\", line 1537, in train\n",
      "    return inner_training_loop(\n",
      "  File \"/Users/sfriedowitz/miniconda3/envs/lm-buddy/lib/python3.10/site-packages/transformers/trainer.py\", line 1672, in _inner_training_loop\n",
      "    model, self.optimizer = self.accelerator.prepare(self.model, self.optimizer)\n",
      "  File \"/Users/sfriedowitz/miniconda3/envs/lm-buddy/lib/python3.10/site-packages/accelerate/accelerator.py\", line 1227, in prepare\n",
      "    result = tuple(\n",
      "  File \"/Users/sfriedowitz/miniconda3/envs/lm-buddy/lib/python3.10/site-packages/accelerate/accelerator.py\", line 1228, in <genexpr>\n",
      "    self._prepare_one(obj, first_pass=True, device_placement=d) for obj, d in zip(args, device_placement)\n",
      "  File \"/Users/sfriedowitz/miniconda3/envs/lm-buddy/lib/python3.10/site-packages/accelerate/accelerator.py\", line 1104, in _prepare_one\n",
      "    return self.prepare_model(obj, device_placement=device_placement)\n",
      "  File \"/Users/sfriedowitz/miniconda3/envs/lm-buddy/lib/python3.10/site-packages/accelerate/accelerator.py\", line 1408, in prepare_model\n",
      "    model = torch.nn.parallel.DistributedDataParallel(model, **kwargs)\n",
      "  File \"/Users/sfriedowitz/miniconda3/envs/lm-buddy/lib/python3.10/site-packages/torch/nn/parallel/distributed.py\", line 797, in __init__\n",
      "    _sync_module_states(\n",
      "  File \"/Users/sfriedowitz/miniconda3/envs/lm-buddy/lib/python3.10/site-packages/torch/distributed/utils.py\", line 292, in _sync_module_states\n",
      "    _sync_params_and_buffers(process_group, module_states, broadcast_bucket_size, src)\n",
      "  File \"/Users/sfriedowitz/miniconda3/envs/lm-buddy/lib/python3.10/site-packages/torch/distributed/utils.py\", line 306, in _sync_params_and_buffers\n",
      "    dist._broadcast_coalesced(\n",
      "RuntimeError: Invalid scalar type\n",
      "2024-02-16 15:09:37,333\tERROR tune.py:1038 -- Trials did not complete: [TorchTrainer_08e3c_00000]\n",
      "2024-02-16 15:09:37,334\tINFO tune.py:1042 -- Total run time: 16.63 seconds (16.62 seconds for the tuning loop).\n"
     ]
    },
    {
     "ename": "TrainingFailedError",
     "evalue": "The Ray Train run failed. Please inspect the previous error messages for a cause. After fixing the issue (assuming that the error is not caused by your own application logic, but rather an error such as OOM), you can restart the run from scratch or continue this run.\nTo continue this run, you can use: `trainer = TorchTrainer.restore(\"/Users/sfriedowitz/ray_results/example-fietuning\")`.\nTo start a new run that will retry on training failures, set `train.RunConfig(failure_config=train.FailureConfig(max_failures))` in the Trainer's `run_config` with `max_failures > 0`, or `max_failures = -1` for unlimited retries.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRayTaskError(RuntimeError)\u001b[0m                Traceback (most recent call last)",
      "\u001b[0;31mRayTaskError(RuntimeError)\u001b[0m: \u001b[36mray::_Inner.train()\u001b[39m (pid=96385, ip=127.0.0.1, actor_id=bf3aee7e1968b8c89f1f5e8a01000000, repr=TorchTrainer)\n  File \"/Users/sfriedowitz/miniconda3/envs/lm-buddy/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 342, in train\n    raise skipped from exception_cause(skipped)\n  File \"/Users/sfriedowitz/miniconda3/envs/lm-buddy/lib/python3.10/site-packages/ray/train/_internal/utils.py\", line 43, in check_for_failure\n    ray.get(object_ref)\nray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::_RayTrainWorker__execute.get_next()\u001b[39m (pid=96405, ip=127.0.0.1, actor_id=b4353c84bc8b6902aefc6ed601000000, repr=<ray.train._internal.worker_group.RayTrainWorker object at 0x11d8edc90>)\n  File \"/Users/sfriedowitz/miniconda3/envs/lm-buddy/lib/python3.10/site-packages/ray/train/_internal/worker_group.py\", line 33, in __execute\n    raise skipped from exception_cause(skipped)\n  File \"/Users/sfriedowitz/miniconda3/envs/lm-buddy/lib/python3.10/site-packages/ray/train/_internal/utils.py\", line 118, in discard_return_wrapper\n    train_func(*args, **kwargs)\n  File \"/Users/sfriedowitz/workspace/lm_buddy/src/lm_buddy/jobs/_entrypoints/finetuning.py\", line 82, in training_function\n    load_and_train(config, artifact_loader)\n  File \"/Users/sfriedowitz/workspace/lm_buddy/src/lm_buddy/jobs/_entrypoints/finetuning.py\", line 62, in load_and_train\n    trainer.train()\n  File \"/Users/sfriedowitz/miniconda3/envs/lm-buddy/lib/python3.10/site-packages/trl/trainer/sft_trainer.py\", line 323, in train\n    output = super().train(*args, **kwargs)\n  File \"/Users/sfriedowitz/miniconda3/envs/lm-buddy/lib/python3.10/site-packages/transformers/trainer.py\", line 1537, in train\n    return inner_training_loop(\n  File \"/Users/sfriedowitz/miniconda3/envs/lm-buddy/lib/python3.10/site-packages/transformers/trainer.py\", line 1672, in _inner_training_loop\n    model, self.optimizer = self.accelerator.prepare(self.model, self.optimizer)\n  File \"/Users/sfriedowitz/miniconda3/envs/lm-buddy/lib/python3.10/site-packages/accelerate/accelerator.py\", line 1227, in prepare\n    result = tuple(\n  File \"/Users/sfriedowitz/miniconda3/envs/lm-buddy/lib/python3.10/site-packages/accelerate/accelerator.py\", line 1228, in <genexpr>\n    self._prepare_one(obj, first_pass=True, device_placement=d) for obj, d in zip(args, device_placement)\n  File \"/Users/sfriedowitz/miniconda3/envs/lm-buddy/lib/python3.10/site-packages/accelerate/accelerator.py\", line 1104, in _prepare_one\n    return self.prepare_model(obj, device_placement=device_placement)\n  File \"/Users/sfriedowitz/miniconda3/envs/lm-buddy/lib/python3.10/site-packages/accelerate/accelerator.py\", line 1408, in prepare_model\n    model = torch.nn.parallel.DistributedDataParallel(model, **kwargs)\n  File \"/Users/sfriedowitz/miniconda3/envs/lm-buddy/lib/python3.10/site-packages/torch/nn/parallel/distributed.py\", line 797, in __init__\n    _sync_module_states(\n  File \"/Users/sfriedowitz/miniconda3/envs/lm-buddy/lib/python3.10/site-packages/torch/distributed/utils.py\", line 292, in _sync_module_states\n    _sync_params_and_buffers(process_group, module_states, broadcast_bucket_size, src)\n  File \"/Users/sfriedowitz/miniconda3/envs/lm-buddy/lib/python3.10/site-packages/torch/distributed/utils.py\", line 306, in _sync_params_and_buffers\n    dist._broadcast_coalesced(\nRuntimeError: Invalid scalar type",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTrainingFailedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Run the job\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mlm_buddy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_job\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/lm_buddy/src/lm_buddy/jobs/__init__.py:26\u001b[0m, in \u001b[0;36mrun_job\u001b[0;34m(config, artifact_loader)\u001b[0m\n\u001b[1;32m     24\u001b[0m     run_simple(simple_config, artifact_loader)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mcase\u001b[39;00m FinetuningJobConfig() \u001b[38;5;28;01mas\u001b[39;00m finetuning_config:\n\u001b[0;32m---> 26\u001b[0m     \u001b[43mrun_finetuning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinetuning_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mcase\u001b[39;00m LMHarnessJobConfig() \u001b[38;5;28;01mas\u001b[39;00m lm_harness_config:\n\u001b[1;32m     28\u001b[0m     run_lm_harness(lm_harness_config, artifact_loader)\n",
      "File \u001b[0;32m~/workspace/lm_buddy/src/lm_buddy/jobs/_entrypoints/finetuning.py:100\u001b[0m, in \u001b[0;36mrun_finetuning\u001b[0;34m(config, artifact_loader)\u001b[0m\n\u001b[1;32m     89\u001b[0m run_config \u001b[38;5;241m=\u001b[39m RunConfig(\n\u001b[1;32m     90\u001b[0m     name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtracking\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mtracking \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     91\u001b[0m     storage_path\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mray\u001b[38;5;241m.\u001b[39mstorage_path,\n\u001b[1;32m     92\u001b[0m     checkpoint_config\u001b[38;5;241m=\u001b[39mCheckpointConfig(num_to_keep\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     93\u001b[0m )\n\u001b[1;32m     94\u001b[0m trainer \u001b[38;5;241m=\u001b[39m TorchTrainer(\n\u001b[1;32m     95\u001b[0m     train_loop_per_worker\u001b[38;5;241m=\u001b[39mtraining_function,\n\u001b[1;32m     96\u001b[0m     train_loop_config\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmodel_dump(),\n\u001b[1;32m     97\u001b[0m     scaling_config\u001b[38;5;241m=\u001b[39mscaling_config,\n\u001b[1;32m     98\u001b[0m     run_config\u001b[38;5;241m=\u001b[39mrun_config,\n\u001b[1;32m     99\u001b[0m )\n\u001b[0;32m--> 100\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining result: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# Register a model artifact if tracking is enabled and Ray saved a checkpoint\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/lm-buddy/lib/python3.10/site-packages/ray/train/base_trainer.py:640\u001b[0m, in \u001b[0;36mBaseTrainer.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    636\u001b[0m result \u001b[38;5;241m=\u001b[39m result_grid[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39merror:\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;66;03m# Raise trainable errors to the user with a message to restore\u001b[39;00m\n\u001b[1;32m    639\u001b[0m     \u001b[38;5;66;03m# or configure `FailureConfig` in a new run.\u001b[39;00m\n\u001b[0;32m--> 640\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m TrainingFailedError(\n\u001b[1;32m    641\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([restore_msg, TrainingFailedError\u001b[38;5;241m.\u001b[39m_FAILURE_CONFIG_MSG])\n\u001b[1;32m    642\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mresult\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merror\u001b[39;00m\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mTrainingFailedError\u001b[0m: The Ray Train run failed. Please inspect the previous error messages for a cause. After fixing the issue (assuming that the error is not caused by your own application logic, but rather an error such as OOM), you can restart the run from scratch or continue this run.\nTo continue this run, you can use: `trainer = TorchTrainer.restore(\"/Users/sfriedowitz/ray_results/example-fietuning\")`.\nTo start a new run that will retry on training failures, set `train.RunConfig(failure_config=train.FailureConfig(max_failures))` in the Trainer's `run_config` with `max_failures > 0`, or `max_failures = -1` for unlimited retries."
     ]
    }
   ],
   "source": [
    "# Run the job\n",
    "\n",
    "lm_buddy.run_job(job_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lm-buddy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
