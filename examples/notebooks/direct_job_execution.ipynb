{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Direct job execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook illustrates how to use LM Buddy as a library to run jobs directly on the host machine.\n",
    "\n",
    "Jobs are executed in the following manner:\n",
    "- Construct an instance of the `lm_buddy.LMBuddy` class\n",
    "- Construct an instance of your desired job configuration\n",
    "- Execute a job via the `LMBuddy.finetune` or `LMBuddy.evaluate` methods\n",
    "\n",
    "**Warning**: This workflow is still considered experimental.\n",
    "Some jobs depend on external services (e.g., W&B, Ray cluster) and host-machine GPU resources,\n",
    "and may not work without a properly configured local environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lm_buddy import LMBuddy\n",
    "from lm_buddy.jobs.configs import (\n",
    "    FinetuningJobConfig,\n",
    "    FinetuningRayConfig,\n",
    "    LMHarnessJobConfig,\n",
    "    LMHarnessEvaluationConfig,\n",
    ")\n",
    "from lm_buddy.integrations.huggingface import (\n",
    "    HuggingFaceRepoConfig,\n",
    "    AutoModelConfig,\n",
    "    TextDatasetConfig,\n",
    "    TrainerConfig,\n",
    "    AdapterConfig,\n",
    ")\n",
    "from lm_buddy.integrations.wandb import WandbRunConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base model to finetune from HuggingFace\n",
    "model_config = AutoModelConfig(\n",
    "    load_from=HuggingFaceRepoConfig(repo_id=\"distilgpt2\"),\n",
    ")\n",
    "\n",
    "# Text dataset for finetuning\n",
    "dataset_config = TextDatasetConfig(\n",
    "    load_from=HuggingFaceRepoConfig(repo_id=\"imdb\"),\n",
    "    split=\"train[:100]\",\n",
    "    text_field=\"text\",\n",
    ")\n",
    "\n",
    "# HuggingFace trainer arguments\n",
    "trainer_config = TrainerConfig(\n",
    "    max_seq_length=256,\n",
    "    per_device_train_batch_size=8,\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=1,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=1,\n",
    "    save_strategy=\"epoch\",\n",
    "    save_steps=1,\n",
    ")\n",
    "\n",
    "# LORA adapter settings\n",
    "adapter_config = AdapterConfig(\n",
    "    peft_type=\"LORA\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.2,\n",
    ")\n",
    "\n",
    "# Define tracking for finetuning run\n",
    "tracking_config = WandbRunConfig(\n",
    "    name=\"example-finetuning\",\n",
    "    project=\"lm-buddy-examples\",  # Update to your project name\n",
    "    entity=\"mozilla-ai\",  # Update to your entity name\n",
    ")\n",
    "\n",
    "# Ray train settings\n",
    "ray_config = FinetuningRayConfig(\n",
    "    use_gpu=False,  # Change to True if GPUs are available on your machine\n",
    "    num_workers=2,\n",
    ")\n",
    "\n",
    "# Full finetuning config\n",
    "finetuning_config = FinetuningJobConfig(\n",
    "    model=model_config,\n",
    "    dataset=dataset_config,\n",
    "    trainer=trainer_config,\n",
    "    adapter=adapter_config,\n",
    "    tracking=tracking_config,\n",
    "    ray=ray_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the job\n",
    "buddy = LMBuddy()\n",
    "buddy.finetune(finetuning_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model to be evaluated\n",
    "# In this case, loading directly a pretrained model from HuggingFace\n",
    "model_config = AutoModelConfig(\n",
    "    load_from=HuggingFaceRepoConfig(repo_id=\"distilgpt2\"),\n",
    ")\n",
    "\n",
    "# Define evaluation tasks and settings\n",
    "evaluation_config = LMHarnessEvaluationConfig(\n",
    "    tasks=[\"hellaswag\"],\n",
    "    limit=10,  # Only run 10 samples per task. Remove for a real run.\n",
    "    num_fewshot=5,\n",
    ")\n",
    "\n",
    "# Define tracking for eval run\n",
    "tracking_config = WandbRunConfig(\n",
    "    name=\"example-lm-harness\",\n",
    "    project=\"lm-buddy-examples\",  # Update to your project name\n",
    "    entity=\"mozilla-ai\",  # Update to your entity name\n",
    ")\n",
    "\n",
    "# Full lm-harness job config\n",
    "lm_harness_config = LMHarnessJobConfig(\n",
    "    model=model_config,\n",
    "    evaluation=evaluation_config,\n",
    "    tracking=tracking_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the job\n",
    "buddy = LMBuddy()\n",
    "eval_results = buddy.evaluate(lm_harness_config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lm-buddy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
