{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "123e34e9-70f8-42ab-b790-b59ddc01b1f3",
   "metadata": {},
   "source": [
    "# Development Ray submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4fc01e",
   "metadata": {},
   "source": [
    "Generally, `lm-buddy` is installed as a pip requirement in the runtime environment of the Ray job.\n",
    "During development, however, it can be helpful to execute a job from a local branch \n",
    "that has not been published to PyPI.\n",
    "\n",
    "This example notebook shows how to bypass the pip requirements section of the Ray runtime environment\n",
    "and instead upload a local copy of the `lm_buddy` Python module directly to Ray."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5518ab35",
   "metadata": {},
   "source": [
    "## File-based submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7c26d9",
   "metadata": {},
   "source": [
    "This demonstrates the basic workflow for submitting an LM Buddy job to Ray\n",
    "from a configuration stored as a local file.\n",
    "\n",
    "The job configuration is stored as a YAML file in a the local `configs` directory,\n",
    "and that directory is specified as the working directory of the Ray runtime environment upon submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd3e4db3-829b-495f-9864-7567bd2ac0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from ray.job_submission import JobSubmissionClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a63dc6-9dbc-498e-8cea-26a63198b783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a submission client bound to a Ray cluster\n",
    "# If using a remote cluster, replace 127.0.0.1 with the head node's IP address.\n",
    "client = JobSubmissionClient(f\"http://127.0.0.1:8265\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5aeb388-d357-47b5-96f0-57e1e2792c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine local module path for the LM Buddy repo\n",
    "# In theory this workflow is possible without having the LM Buddy package installed locally,\n",
    "# but this is a convenient means to access the local module path\n",
    "import lm_buddy\n",
    "\n",
    "lm_buddy_module = Path(lm_buddy.__file__).parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25075f6f-b045-446e-b4c4-27ec16b03be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the runtime environment for your job submission\n",
    "# py_modules contains the path to the local LM Buddy module directory\n",
    "# pip contains an export of the dependencies for the LM Buddy package (see CONTRIBUTING.md for how to generate)\n",
    "runtime_env = {\n",
    "    \"working_dir\": \"configs\",\n",
    "    \"env_vars\": {\"WANDB_API_KEY\": os.environ[\"WANDB_API_KEY\"]},  # If running a job that uses W&B\n",
    "    \"py_modules\": [str(lm_buddy_module)],\n",
    "    \"pip\": \"requirements.txt\",  # See CONTRIBUTING.md for how to generate this\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af062383-9103-4779-a225-a300a8f2f6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit the job to the Ray cluster\n",
    "# Note: LM Buddy is invoked by 'python -m lm_buddy run ...' since the CLI is not installed in the environment\n",
    "client.submit_job(\n",
    "    entrypoint=f\"python -m lm_buddy run simple --config simple_config.yaml\",\n",
    "    runtime_env=runtime_env,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff88c2f6",
   "metadata": {},
   "source": [
    "## Iterative submission with temporary config files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7191752e-c377-49a1-b90f-c9b1b8e308ea",
   "metadata": {},
   "source": [
    "It is also possible to submit LM Buddy jobs using a fully Jupyter-driven workflow without external file dependencies.\n",
    "In this case, the job configuration is instantiated in your Python script and written to a temporary directory for submission.\n",
    "The Ray working directory is based off this temporary YAML file location.\n",
    "\n",
    "This approach is convenient if you want to run sweeps over parameter ranges, need to modify your config frequently, and use a Python script/Jupyter notebook as your local \"driver\" for the workflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b26d777",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T19:26:42.108641Z",
     "start_time": "2024-02-12T19:26:41.116723Z"
    }
   },
   "outputs": [],
   "source": [
    "# Required imports\n",
    "from pathlib import Path\n",
    "from ray.job_submission import JobSubmissionClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac2c691a-ebed-4bf5-af23-eaeab15cd4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a submission client bound to a Ray cluster\n",
    "# If using a remote cluster, replace 127.0.0.1 with the head node's IP address.\n",
    "client = JobSubmissionClient(f\"http://127.0.0.1:8265\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab330517-22a6-40f5-876a-e51bb8f57954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine local module path for the LM Buddy repo\n",
    "# In theory this workflow is possible without having the LM Buddy package installed locally,\n",
    "# but this is a convenient means to access the local module path\n",
    "import lm_buddy\n",
    "\n",
    "lm_buddy_module = Path(lm_buddy.__file__).parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee4063a-9aac-47fe-9339-2d3b61045cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from lm_buddy.jobs.simple import SimpleJobConfig\n",
    "\n",
    "# Generate job configs programatically for sweeps over parameter ranges\n",
    "magic_numbers = [0, 10, 20, 40]\n",
    "\n",
    "for number in magic_numbers:\n",
    "    # Instantitate config in your workflow script\n",
    "    # You may also want to read a \"base\" config from file with some suitable defaults\n",
    "    config = SimpleJobConfig(magic_number=number)\n",
    "\n",
    "    # `config_path` is the fully qualified path to the config file on your local filesystem\n",
    "    with config.to_tempfile(name=\"config.yaml\") as config_path:\n",
    "        # `config_path.parent` is the working directory\n",
    "        runtime_env = {\n",
    "            \"working_dir\": str(config_path.parent),\n",
    "            \"env_vars\": {\"WANDB_API_KEY\": os.environ[\"WANDB_API_KEY\"]},\n",
    "            \"py_modules\": [str(lm_buddy_module)],\n",
    "            \"pip\": \"requirements.txt\",  # See CONTRIBUTING.md for how to generate this\n",
    "        }\n",
    "\n",
    "        # `config_path.name` is the file name within the working directory, i.e., \"config.yaml\"\n",
    "        client.submit_job(\n",
    "            entrypoint=f\"python -m lm_buddy run simple --config {config_path.name}\",\n",
    "            runtime_env=runtime_env,\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
